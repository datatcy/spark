{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e22af67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/21 17:41:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('database').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da3bf51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (col,expr,count,countDistinct,to_date,date_add,year,month,lag,lead,rank,max,min,round,\n",
    "                                   sum,when,lit,desc,coalesce,abs\n",
    "                                  )\n",
    "from pyspark.sql.types import (StructField,StructType,\n",
    "                    IntegerType,StringType,DateType )\n",
    "from pyspark.sql import Window\n",
    "\n",
    "path  = '/Users/francispaulraj/Training/interview'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10d2db6",
   "metadata": {},
   "source": [
    "#### 01 Find Customers With Positive Revenue this Year EP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0b1354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_schema = StructType([ \n",
    "                             StructField('customer_id',IntegerType()),\n",
    "                             StructField('year',DateType()),\n",
    "                             StructField('revenue',IntegerType())\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "06e53baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/1_customer.csv')\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f78c79ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- revenue: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bde71f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|customer_id|\n",
      "+-----------+\n",
      "|          1|\n",
      "|          4|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_df.filter( (col(('year')) == lit('2021')) & (col('revenue') >= 0 )).select('customer_id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84791235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|customer_id|\n",
      "+-----------+\n",
      "|          1|\n",
      "|          4|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_df.createOrReplaceTempView('customerdf')\n",
    "\n",
    "spark.sql('select customer_id from customerdf where year == \"2021\" and revenue >= 0').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5a5afd",
   "metadata": {},
   "source": [
    "#### 02 Customers Who Never Order E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "447a07c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/2_customers.csv')\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df261062",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/2_orders.csv')\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf93cef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customers_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2c50c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- customerid: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.printSchema() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9efb4e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| name|\n",
      "+-----+\n",
      "|Henry|\n",
      "|  Max|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customers_df.join(orders_df,customers_df.id ==orders_df.customerid,'leftanti' ).select('name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "394304e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| name|\n",
      "+-----+\n",
      "|Henry|\n",
      "|  Max|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customers_df.createOrReplaceTempView('customersdf')\n",
    "orders_df.createOrReplaceTempView('ordersdf')\n",
    "\n",
    "spark.sql('select name from customersdf left anti join ordersdf on customersdf.id == ordersdf.customerid').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f749ae45",
   "metadata": {},
   "source": [
    "#### 03 Calculate Special Bonus E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93d3cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/3_employees.csv')\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6099117a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d140fda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|employee_id|bonus|\n",
      "+-----------+-----+\n",
      "|          2|    0|\n",
      "|          3|    0|\n",
      "|          7| 7400|\n",
      "|          8|    0|\n",
      "|          9| 7700|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.withColumn('bonus',when(col('name').rlike('^M'),0)\\\n",
    "                        .when(col('employee_id')%2==1,col('salary')).otherwise(0)).select('employee_id','bonus').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e604cfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|employee_id|bonus|\n",
      "+-----------+-----+\n",
      "|          2|    0|\n",
      "|          3|    0|\n",
      "|          7| 7400|\n",
      "|          8|    0|\n",
      "|          9| 7700|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.createOrReplaceTempView('employeesdf')\n",
    "\n",
    "spark.sql('select employee_id,case when name rlike \"^M\" then 0 \\\n",
    "                                   when employee_id %2 == 1 then salary \\\n",
    "                                   else 0 end as bonus from employeesdf').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc3d6ee",
   "metadata": {},
   "source": [
    "#### 04 Combine Two Tables E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "400d4721",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/4_person.csv')\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "29d1327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "address_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/4_address.csv')\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0023ed8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- personid: integer (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- firstname: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "969df949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- addressid: integer (nullable = true)\n",
      " |-- personid: integer (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "address_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "21802ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------------+--------+\n",
      "|firstname|lastname|         city|   state|\n",
      "+---------+--------+-------------+--------+\n",
      "|    Allen|    Wang|         null|    null|\n",
      "|      Bob|   Alice|New York City|New York|\n",
      "+---------+--------+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person_df.join(address_df,person_df.personid == address_df.personid,'left').select('firstname','lastname','city','state').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "950a0ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------------+--------+\n",
      "|firstname|lastname|         city|   state|\n",
      "+---------+--------+-------------+--------+\n",
      "|    Allen|    Wang|         null|    null|\n",
      "|      Bob|   Alice|New York City|New York|\n",
      "+---------+--------+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person_df.createOrReplaceTempView('persondf')\n",
    "address_df.createOrReplaceTempView('addressdf')\n",
    "\n",
    "spark.sql('select firstname,lastname,city,state  from addressdf \\\n",
    "                  right join persondf on persondf.personid == addressdf.personid').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12204895",
   "metadata": {},
   "source": [
    "#### 05 Sellers With No Sales EP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6714c4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_schema = StructType([ \n",
    "                             StructField('order_id',IntegerType()),\n",
    "                             StructField('sale_date',DateType()),\n",
    "                             StructField('order_cost',IntegerType()),\n",
    "                             StructField('customer_id',IntegerType()),\n",
    "                             StructField('seller_id',IntegerType())\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "23638ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/5_customer.csv')\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7c88322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/5_orders.csv')\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d5cc23e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seller_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/5_seller.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3d623fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customerid: integer (nullable = true)\n",
      " |-- customername: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2626752d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- sale_date: string (nullable = true)\n",
      " |-- order_cost: integer (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- seller_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5eb9c5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- seller_iid: integer (nullable = true)\n",
      " |-- seller_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seller_df.printSchema() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "735ae37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+-----------+---------+\n",
      "|order_id| sale_date|order_cost|customer_id|seller_id|\n",
      "+--------+----------+----------+-----------+---------+\n",
      "|       1|2020-03-01|      1500|        101|        1|\n",
      "|       2|2020-05-25|      2400|        102|        2|\n",
      "|       3|2019-05-25|       800|        101|        3|\n",
      "|       4|2020-09-13|      1000|        103|        2|\n",
      "|       5|2019-02-11|       700|        101|        2|\n",
      "+--------+----------+----------+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1f94797f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|seller_iid|seller_name|\n",
      "+----------+-----------+\n",
      "|         1|     Daniel|\n",
      "|         2|  Elizabeth|\n",
      "|         3|      Frank|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seller_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4f369ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|seller_name|\n",
      "+-----------+\n",
      "|      Frank|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order20 = orders_df.filter(year('sale_date') == lit('2020')).select('seller_id')\n",
    "year20 = [order20.collect()[i][0] for i in range(0,len(order20.collect()))]\n",
    "seller_df.filter(~col('seller_iid').isin(year20)).select('seller_name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4eef92ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|seller_name|\n",
      "+-----------+\n",
      "|      Frank|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.createOrReplaceTempView('ordersdf')\n",
    "seller_df.createOrReplaceTempView('sellerdf')\n",
    "\n",
    "spark.sql('select seller_name from sellerdf where seller_iid not in ( \\\n",
    "             select seller_id from ordersdf where year(sale_date) == \"2020\"  )').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16956255",
   "metadata": {},
   "source": [
    "#### 06 Top Travellers E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "dd6a422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/6_users.csv')\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1dd5c1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "riders_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/6_riders.csv')\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4b13c8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "be4cad64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- distance: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "riders_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2a742d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|    name|usrdis|\n",
      "+--------+------+\n",
      "|   Elvis|   450|\n",
      "|     Lee|   450|\n",
      "|     Bob|   317|\n",
      "|Jonathan|   312|\n",
      "|    Alex|   222|\n",
      "|   Alice|   120|\n",
      "|  Donald|     0|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.join(riders_df,users_df.id == riders_df.user_id,'left').groupBy('name')\\\n",
    "            .agg(sum(col('distance')).alias('usr_distanct'))\\\n",
    "            .select('name',coalesce(col('usr_distanct'),lit('0')).alias('usrdis')).orderBy(desc('usrdis')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1efd3bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|    name|distance|\n",
      "+--------+--------+\n",
      "|   Elvis|     450|\n",
      "|     Lee|     450|\n",
      "|     Bob|     317|\n",
      "|Jonathan|     312|\n",
      "|    Alex|     222|\n",
      "|   Alice|     120|\n",
      "|  Donald|       0|\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.createOrReplaceTempView('usersdf')\n",
    "riders_df.createOrReplaceTempView('ridersdf')\n",
    "\n",
    "spark.sql('select name, coalesce(sum(distance),0 ) as distance from usersdf left  \\\n",
    "              join ridersdf on usersdf.id == ridersdf.user_id group by name order by distance desc').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2db6b38",
   "metadata": {},
   "source": [
    "#### 07 Sales Person E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9fe09b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "salesperson_schema = StructType([ \n",
    "                 StructField('sales_id',IntegerType()),\n",
    "                 StructField('name',StringType()),\n",
    "                 StructField('salary',IntegerType()),\n",
    "                 StructField('commission_rate',IntegerType()),\n",
    "                 StructField('hire_date',DateType())\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "5b7fabe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_schema = StructType([ \n",
    "                 StructField('order_id',IntegerType()),\n",
    "                 StructField('order_date',DateType()),\n",
    "                 StructField('com_id',IntegerType()),\n",
    "                 StructField('sales_id',IntegerType()),\n",
    "                 StructField('amount',IntegerType())\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a02637b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "salesperson_df = (spark.read\n",
    "               .option('header',True)\n",
    "               #.schema(salesperson_schema) \n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/7_salesperson.csv'))\n",
    "               #.withColumn('hire_date',to_date('hire_date','MM-dd-yyyy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "52df5017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sales_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- commission_rate: integer (nullable = true)\n",
      " |-- hire_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salesperson_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1fd661c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = (spark.read\n",
    "               .option('header',True)\n",
    "               #.schema(order_schema)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/7_orders.csv'))\n",
    "               #.withColumn('order_date',to_date('order_date','MM-dd-yyyy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "48267b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- com_id: integer (nullable = true)\n",
      " |-- sales_id: integer (nullable = true)\n",
      " |-- amount: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e18d43f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/7_company.csv')\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "cdfeed41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- com_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "company_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "3559ce02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|name|\n",
      "+----+\n",
      "| Amy|\n",
      "|Mark|\n",
      "|Alex|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders = orders_df.join(salesperson_df,orders_df.sales_id == salesperson_df.sales_id,'right') \\\n",
    "         .join(company_df,orders_df.com_id == company_df.com_id,'left')\\\n",
    "         .select(coalesce(orders_df.com_id,lit('0')).alias('com_id'),salesperson_df.name)\n",
    "\n",
    "red = orders.filter(col('com_id').isin([1])).select('name').collect()\n",
    "x = [red[i][0]   for i in range(0,len(red))]\n",
    "orders.filter(~col('name').isin(x)).select('name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "43099e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|name|\n",
      "+----+\n",
      "| Amy|\n",
      "|Mark|\n",
      "|Alex|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salesperson_df.createOrReplaceTempView('salespersondf')\n",
    "orders_df.createOrReplaceTempView('ordersdf')\n",
    "company_df.createOrReplaceTempView('companydf')\n",
    "\n",
    "spark.sql('with main as (select coalesce(ordersdf.com_id,0) as com_id,salespersondf.name  \\\n",
    "                         from ordersdf right join salespersondf on ordersdf.sales_id == salespersondf.sales_id),\\\n",
    "                 red as (select main.name from main join companydf on main.com_id == companydf.com_id where companydf.name == \"RED\") \\\n",
    "                         select main.name from main where name not in (select name from red) \\\n",
    "                        ').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e944453",
   "metadata": {},
   "source": [
    "#### 08 The Latest Login in 2020 E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "059eaf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logins_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/8_logins.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "a994d78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- time_stamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logins_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "935ad394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|user_id|    max(time_stamp)|\n",
      "+-------+-------------------+\n",
      "|      6|2020-06-30 15:06:07|\n",
      "|      8|2020-12-30 00:46:50|\n",
      "|      2|2020-01-16 02:49:50|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logins_df.filter(year('time_stamp') == lit('2020')).groupBy('user_id').agg(max(col('time_stamp'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "921afbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|user_id|         time_stamp|\n",
      "+-------+-------------------+\n",
      "|      6|2020-06-30 15:06:07|\n",
      "|      8|2020-12-30 00:46:50|\n",
      "|      2|2020-01-16 02:49:50|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logins_df.createOrReplaceTempView('loginsdf')\n",
    "\n",
    "spark.sql('select user_id,max(time_stamp) as time_stamp from \\\n",
    "          loginsdf where year(time_stamp) == \"2020\" group by user_id').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e6bcc3",
   "metadata": {},
   "source": [
    "#### 09 Game Play Analysis E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "7e7fa0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logins_schema = StructType([ \n",
    "                 StructField('player_id',IntegerType()),\n",
    "                 StructField('device_id',IntegerType()),\n",
    "                 StructField('event_date',DateType()),\n",
    "                 StructField('games_played',IntegerType()),\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "82f9e8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .schema(logins_schema)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/9_activity.csv')\n",
    "               .withColumn('event_date',to_date('event_date','MM-dd--yyyy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "67b6317c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- player_id: integer (nullable = true)\n",
      " |-- device_id: integer (nullable = true)\n",
      " |-- event_date: date (nullable = true)\n",
      " |-- games_played: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "activity_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "7a178361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|player_id|event_date|\n",
      "+---------+----------+\n",
      "|        1|2016-03-01|\n",
      "|        2|2017-06-25|\n",
      "|        3|2016-03-02|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "activity_df.groupBy('player_id').agg(min(col('event_date')).alias('event_date')).orderBy('player_id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "d2644fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|player_id|event_date|\n",
      "+---------+----------+\n",
      "|        1|2016-03-01|\n",
      "|        2|2017-06-25|\n",
      "|        3|2016-03-02|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "activity_df.createOrReplaceTempView('activitydf')\n",
    "\n",
    "spark.sql('select player_id,min(event_date) as event_date from activitydf group by player_id order by player_id').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993b33c4",
   "metadata": {},
   "source": [
    "#### 10 Warehouse Manager EP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "a08d28cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "warehouse_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/10_warehouse.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "c3a71fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/10_products.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "bf2d6ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- units: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warehouse_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "a2ffacab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- width: integer (nullable = true)\n",
      " |-- length: integer (nullable = true)\n",
      " |-- height: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "e398f3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----+------+------+--------+----------+-----+\n",
      "|product_id|product_name|width|length|height|    name|product_id|units|\n",
      "+----------+------------+-----+------+------+--------+----------+-----+\n",
      "|         1|       LC-TV|    5|    50|    40|LCHouse2|         1|    2|\n",
      "|         1|       LC-TV|    5|    50|    40|LCHouse1|         1|    1|\n",
      "|         2| LC-KeyChain|    5|     5|     5|LCHouse2|         2|    2|\n",
      "|         2| LC-KeyChain|    5|     5|     5|LCHouse1|         2|   10|\n",
      "|         3|    LC-Phone|    2|    10|    10|LCHouse1|         3|    5|\n",
      "|         4|  LC-T-Shirt|    4|    10|    20|LCHouse3|         4|    1|\n",
      "+----------+------------+-----+------+------+--------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products_df.join(warehouse_df,products_df.product_id == warehouse_df.product_id,'inner').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "9842e0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|warehouse_name|space|\n",
      "+--------------+-----+\n",
      "|      LCHouse1|12250|\n",
      "|      LCHouse2|20250|\n",
      "|      LCHouse3|  800|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products_df.withColumn('size',col('width') * col('length') * col('height') )\\\n",
    "        .join(warehouse_df,products_df.product_id == warehouse_df.product_id,'inner')\\\n",
    "        .withColumn('tot_spacee',col('size')*col('units'))\\\n",
    "        .groupby('name').agg(sum(col('tot_spacee')).alias('space'))\\\n",
    "        .select(col('name').alias('warehouse_name'),'space').orderBy('name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "f156b7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----+-----+\n",
      "|product_id|product_name| size|units|\n",
      "+----------+------------+-----+-----+\n",
      "|         1|       LC-TV|10000|    2|\n",
      "|         1|       LC-TV|10000|    1|\n",
      "|         2| LC-KeyChain|  125|    2|\n",
      "|         2| LC-KeyChain|  125|   10|\n",
      "|         3|    LC-Phone|  200|    5|\n",
      "|         4|  LC-T-Shirt|  800|    1|\n",
      "+----------+------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warehouse_df.createOrReplaceTempView('warehousedf')\n",
    "products_df.createOrReplaceTempView('productsdf')\n",
    "\n",
    "spark.sql('select productsdf.product_id,product_name,(width * length * height)as size,units from productsdf join \\\n",
    "              warehousedf on productsdf.product_id == warehousedf.product_id \\\n",
    "          ').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "bdba669f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|warehouse_name| size|\n",
      "+--------------+-----+\n",
      "|      LCHouse1|12250|\n",
      "|      LCHouse2|20250|\n",
      "|      LCHouse3|  800|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select name as warehouse_name,sum(tot_size) as size from \\\n",
    "          (select name,((width * length * height) * units) as tot_size from productsdf join \\\n",
    "              warehousedf on productsdf.product_id == warehousedf.product_id) group by name  order by name\\\n",
    "          ').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83a1921",
   "metadata": {},
   "source": [
    "#### 11 Customer Placing the Largest Number of Orders E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8eff8a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/11_orders.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d266816e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- oder_number: integer (nullable = true)\n",
      " |-- customer_number: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ddf36e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|customer_number|\n",
      "+---------------+\n",
      "|              3|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.groupBy('customer_number').agg(count(col('oder_number')).alias('order'))\\\n",
    "                .orderBy(desc('order')).limit(1).select('customer_number').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df933fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|customer_number|\n",
      "+---------------+\n",
      "|              3|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.createOrReplaceTempView('ordersdf')\n",
    "\n",
    "spark.sql('select customer_number from (select customer_number,count(\"order_number\") as order from ordersdf \\\n",
    "                    group by customer_number order by order desc limit 1)').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d15da03",
   "metadata": {},
   "source": [
    "#### 12 Find Total Time Spent by Each Employee E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01201503",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/12_employees.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "71f9babb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: integer (nullable = true)\n",
      " |-- event_day: string (nullable = true)\n",
      " |-- in_time: integer (nullable = true)\n",
      " |-- out_time: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dee94396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+------------+\n",
      "|emp_id|       day|sum(minutes)|\n",
      "+------+----------+------------+\n",
      "|     1|2020-11-28|         173|\n",
      "|     2|2020-11-28|          30|\n",
      "|     1|2020-12-03|          41|\n",
      "|     2|2020-12-09|          27|\n",
      "+------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.select(col('event_day').alias('day'),'emp_id',abs(col('in_time') - col('out_time')).alias('minutes') )\\\n",
    "            .groupBy('emp_id','day').agg(sum(col('minutes'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d523fd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-------+\n",
      "|       day|emp_id|minutes|\n",
      "+----------+------+-------+\n",
      "|2020-11-28|     1|    173|\n",
      "|2020-11-28|     2|     30|\n",
      "|2020-12-03|     1|     41|\n",
      "|2020-12-09|     2|     27|\n",
      "+----------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.createOrReplaceTempView('employeesdf')\n",
    "\n",
    "spark.sql(' select day,emp_id,sum(minutes) as minutes from  \\\n",
    "          (select emp_id,event_day as day, abs(in_time - out_time) as minutes from employeesdf) group by emp_id,day ').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fe5ee1",
   "metadata": {},
   "source": [
    "#### 13 Immediate Food Delivery I EP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3daa870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/13_delivery.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7c1bdaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- delivery_id: integer (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- customer_pref_delivery_date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delivery_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6e8ea575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|immediate_percentage|\n",
      "+--------------------+\n",
      "|                0.33|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delivery_df.filter(col('order_date') == col('customer_pref_delivery_date'))\\\n",
    "        .select( round(count(col('delivery_id'))/delivery_df.selectExpr(\"count(delivery_id)\").collect()[0][0],2)\\\n",
    "        .alias('immediate_percentage')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "76e97f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|immediate_percentage|\n",
      "+--------------------+\n",
      "|                0.33|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delivery_df.createOrReplaceTempView('deliverydf')\n",
    "spark.sql('select round(a.two/b.one,2) as immediate_percentage from \\\n",
    "          (select count(\"delivery_id\") as one from deliverydf) b, \\\n",
    "           (select count(\"delivery_id\") as two from deliverydf \\\n",
    "                   where order_date == customer_pref_delivery_date) a').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b0058d",
   "metadata": {},
   "source": [
    "#### 14 Bank Account Summary II E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f4def714",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/14_users.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "38742e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/14_transaction.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9477d1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- account: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "401c183c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- trans_id: integer (nullable = true)\n",
      " |-- account: integer (nullable = true)\n",
      " |-- amount: integer (nullable = true)\n",
      " |-- transacted_on: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transaction_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ca142358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "| name|balance|\n",
      "+-----+-------+\n",
      "|Alice|  11000|\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transaction_df.groupBy('account').agg(sum(col(('amount'))).alias('balance'))\\\n",
    "        .join(users_df,transaction_df.account == users_df.account,'inner') \\\n",
    "        .filter(col('balance') >= lit('10000')).select('name','balance').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "0cd35c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "| name|balance|\n",
      "+-----+-------+\n",
      "|Alice|  11000|\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.createOrReplaceTempView('usersdf')\n",
    "transaction_df.createOrReplaceTempView('transactiondf')\n",
    "\n",
    "spark.sql(' select name, sum(amount) as balance from transactiondf \\\n",
    "            join usersdf on usersdf.account == transactiondf.account group by name having balance >= 10000 \\\n",
    "         ').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eb533d",
   "metadata": {},
   "source": [
    "#### 15 Duplicate Emails E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c08dcc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/15_person.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "534af3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "81fc2a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|  email|\n",
      "+-------+\n",
      "|a@b.com|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person_df.filter(col('email') == person_df.groupBy('email').agg(count(col('email')).alias('cnt_email'))\\\n",
    "    .orderBy(desc(col('cnt_email'))).select('email').first()[:][0]).select('email').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "bc999e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|  email|\n",
      "+-------+\n",
      "|a@b.com|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person_df.createOrReplaceTempView('persondf')\n",
    "\n",
    "spark.sql('select email from persondf group by email having count(email) >=2 ').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0369299c",
   "metadata": {},
   "source": [
    "#### 16 Actors and Directors Who Cooperated At Least Three Times E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "68d05e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "actordirector_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/16_actordirector.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5bc670fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- actor_id: integer (nullable = true)\n",
      " |-- director_id: integer (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "actordirector_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "386770a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|actor_id|director_id|\n",
      "+--------+-----------+\n",
      "|       1|          1|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = actordirector_df.groupBy('actor_id','director_id').agg(count(col('director_id')).alias('cnt')).orderBy(desc('cnt')).first()[2]\n",
    "\n",
    "actordirector_df.groupBy('actor_id','director_id').agg(count(col('director_id')).alias('cnt'))\\\n",
    "        .filter(col('cnt') == x).select('actor_id','director_id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "71a0a5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|actor_id|director_id|\n",
      "+--------+-----------+\n",
      "|       1|          1|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "actordirector_df.createOrReplaceTempView('actordirectordf')\n",
    "\n",
    "spark.sql(' select actor_id,director_id from  \\\n",
    "              (select actor_id,director_id,count(director_id) as cnt \\\n",
    "              from actordirectordf group by actor_id,director_id order by cnt desc limit 1) ').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75684d94",
   "metadata": {},
   "source": [
    "#### 17  Customer Order Frequency EP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8c6b6065",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/17_customers.csv')\n",
    "               .withColumnRenamed('customer_id','cus_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "01c02c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/17_product.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "56dcaf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/17_orders.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "75e15b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cus_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customers_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f493998b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b97b27b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "603769c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|cus_id|   name|\n",
      "+------+-------+\n",
      "|     1|Winston|\n",
      "+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.filter(month(col('order_date')).isin([6,7])) \\\n",
    "    .join(product_df,orders_df.product_id == product_df.product_id,'inner') \\\n",
    "    .select('customer_id',month('order_date').alias('month'),(col('quantity') * col('price')).alias('amount')) \\\n",
    "    .join(customers_df,orders_df.customer_id == customers_df.cus_id,'inner')\\\n",
    "    .groupBy('cus_id','month','name').agg(sum(col('amount')).alias('amount')).filter(col('amount') >= 100) \\\n",
    "    .groupBy('cus_id','name').agg(count(col('month')).alias('cnt_month')).filter(col('cnt_month') >= 2)\\\n",
    "    .select('cus_id','name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "45b94355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|cus_id|   name|\n",
      "+------+-------+\n",
      "|     1|Winston|\n",
      "+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.createOrReplaceTempView('ordersdf')\n",
    "product_df.createOrReplaceTempView('productdf')\n",
    "customers_df.createOrReplaceTempView('customersdf')\n",
    "\n",
    "spark.sql('with one as (select customer_id,(quantity * price) as amount,month(order_date) as month from ordersdf \\\n",
    "                        join productdf on ordersdf.product_id == productdf.product_id where month(order_date) in (6,7)), \\\n",
    "                two as (select cus_id,name,month,sum(amount) as amount from customersdf \\\n",
    "                        join one on customersdf.cus_id == one.customer_id  group by cus_id,name,month having amount >= 100) \\\n",
    "                       select cus_id,name from two group by cus_id,name having count(amount) >= 2 \\\n",
    "          ').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042ca588",
   "metadata": {},
   "source": [
    "#### 18 Daily Leads and Partners E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "baaf0f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "dailysaless_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/18_dailysales.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "eef2cf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_id: string (nullable = true)\n",
      " |-- make_name: string (nullable = true)\n",
      " |-- lead_id: integer (nullable = true)\n",
      " |-- partner_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dailysaless_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "272e80a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------+---------+\n",
      "|  date_id|make_name|lead_id|partne_id|\n",
      "+---------+---------+-------+---------+\n",
      "|2020-12-7|   toyota|      1|        2|\n",
      "|2020-12-8|   toyota|      2|        3|\n",
      "|2020-12-8|    honda|      2|        2|\n",
      "|2020-12-7|    honda|      3|        2|\n",
      "+---------+---------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dailysaless_df.groupBy('date_id','make_name')\\\n",
    "              .agg(countDistinct(col('lead_id')).alias('lead_id'),countDistinct(col('partner_id')).alias('partne_id'))\\\n",
    "              .orderBy(desc('make_name')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "723cda7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------+----------+\n",
      "|  date_id|make_name|lead_id|partner_id|\n",
      "+---------+---------+-------+----------+\n",
      "|2020-12-8|   toyota|      2|         3|\n",
      "|2020-12-7|   toyota|      1|         2|\n",
      "|2020-12-7|    honda|      3|         2|\n",
      "|2020-12-8|    honda|      2|         2|\n",
      "+---------+---------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dailysaless_df.createOrReplaceTempView('dailysalessdf')\n",
    "\n",
    "spark.sql('select date_id,make_name,count(distinct lead_id) as lead_id,count(distinct partner_id) as partner_id \\\n",
    "           from dailysalessdf group by date_id,make_name order by make_name desc').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2353d1f",
   "metadata": {},
   "source": [
    "#### 19 Friendly Movies Streamed Last Month EP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "47d7f480",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvprogram_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/19_tvprogram.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e97a1bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/19_content.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "698636ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- program_date: string (nullable = true)\n",
      " |-- content_id: integer (nullable = true)\n",
      " |-- channel: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tvprogram_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4015f30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- content_id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- kids_content: string (nullable = true)\n",
      " |-- content_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "content_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8f3cc527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|  title|\n",
      "+-------+\n",
      "|Aladdin|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tvprogram_df.filter(month(col('program_date')) == 6)\\\n",
    "            .join(content_df,content_df.content_id == tvprogram_df.content_id,'inner')\\\n",
    "          .filter(col('kids_content') == lit('Y')).select('title').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a858ce5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|  title|\n",
      "+-------+\n",
      "|Aladdin|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tvprogram_df.createOrReplaceTempView('tvprogramdf')\n",
    "content_df.createOrReplaceTempView('contentdf')\n",
    "\n",
    "spark.sql('select title from tvprogramdf join contentdf on tvprogramdf.content_id == contentdf.content_id \\\n",
    "              where kids_content == \"Y\" and month(program_date) == 6  ').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a3ec04",
   "metadata": {},
   "source": [
    "#### 20 Rearrange Products Table E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d94b7586",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/20_products.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cec59a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- store1: integer (nullable = true)\n",
      " |-- store2: integer (nullable = true)\n",
      " |-- store3: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1b7b1cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-----+\n",
      "|product_id| store|value|\n",
      "+----------+------+-----+\n",
      "|         0|store1|   95|\n",
      "|         0|store2|  100|\n",
      "|         0|store3|  105|\n",
      "|         1|store1|   70|\n",
      "|         1|store3|   80|\n",
      "+----------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products_df.selectExpr(\n",
    "    \"product_id\",\n",
    "    \"stack(3, 'store1', store1, 'store2', store2, 'store3', store3) as (store, value)\"\n",
    ").filter(~col('value').isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6f4b3749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+------+\n",
      "|product_id|store1|store2|store3|\n",
      "+----------+------+------+------+\n",
      "|         0|    95|   100|   105|\n",
      "|         1|    70|  null|    80|\n",
      "+----------+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9d1cda23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-----+\n",
      "|product_id| store|value|\n",
      "+----------+------+-----+\n",
      "|         0|store1|   95|\n",
      "|         1|store1|   70|\n",
      "|         0|store2|  100|\n",
      "|         0|store3|  105|\n",
      "|         1|store3|   80|\n",
      "+----------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products_df.createOrReplaceTempView('productsdf')\n",
    "\n",
    "spark.sql(' select * from (SELECT product_id, \"store1\" AS store, store1 AS value FROM productsdf \\\n",
    "            UNION ALL \\\n",
    "            SELECT product_id, \"store2\" AS store, store2 AS value FROM productsdf \\\n",
    "            UNION ALL \\\n",
    "            SELECT product_id, \"store3\" AS store, store3 AS value FROM productsdf) where value is not null \\\n",
    "         ').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415ecb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' spark.sql(\"\"\"\n",
    "    SELECT product_id,\n",
    "           store,\n",
    "           value\n",
    "    FROM productsdf\n",
    "    LATERAL VIEW explode(array(\n",
    "        struct('store1', store1),\n",
    "        struct('store2', store2),\n",
    "        struct('store3', store3)\n",
    "    )) AS store_value\n",
    "    SELECT product_id, store_value.col1 as store, store_value.col2 as value\n",
    "\"\"\") '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873ccee1",
   "metadata": {},
   "source": [
    "#### 21 Shortest Distance in a Line EP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "12414d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/21_point.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1441e59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- x: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "point_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "87f5b798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|min_distancee|\n",
      "+-------------+\n",
      "|            1|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/15 22:17:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "window_spec = Window.orderBy('x')\n",
    "point_df.withColumn('xx',lag('x',1).over(window_spec)).select(expr('x-xx')\\\n",
    "                        .alias('xxx')).agg(min('xxx').alias('min_distancee')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "8ebca3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|min_distance|\n",
      "+------------+\n",
      "|           1|\n",
      "+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/15 22:17:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "point_df.createOrReplaceTempView('pointdf')\n",
    "spark.sql('with one as (select x,lag(x) over(order by x) as xx from pointdf) \\\n",
    "                   select min(x - xx) as min_distance from one').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d5c827",
   "metadata": {},
   "source": [
    "#### 22 Employees With Missing Information E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "05596a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/22_employees.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "967b97c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/22_salaries.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "8a98d6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "ed008aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: integer (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salaries_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "60a014cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|employee_id|\n",
      "+-----------+\n",
      "|          1|\n",
      "|          2|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.join(salaries_df,employees_df.employee_id == salaries_df.employee_id,'outer')\\\n",
    "            .filter(col('name').isNull() | col('salary').isNull())\\\n",
    "            .select(coalesce(employees_df.employee_id,salaries_df.employee_id).alias('employee_id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "dbdd9196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|employee_id|\n",
      "+-----------+\n",
      "|          1|\n",
      "|          2|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salaries_df.createOrReplaceTempView('salariesdf')\n",
    "employees_df.createOrReplaceTempView('employeesdf')\n",
    "\n",
    "spark.sql(' with emp as (select employee_id as emp_id,name from employeesdf), \\\n",
    "              salary as (select employee_id,salary from salariesdf), \\\n",
    "                xxxx as (select emp_id,name,employee_id,salary from emp \\\n",
    "                         full outer join salary on emp.emp_id == salary.employee_id) \\\n",
    "                         select coalesce(emp_id,employee_id) as employee_id from xxxx where name is null or salary is null').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8801326",
   "metadata": {},
   "source": [
    "#### 23 Find the Team Size EP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "540eb1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = (spark.read\n",
    "               .option('header',True)\n",
    "               .option('inferSchema',True)\n",
    "               .format('csv')\n",
    "               .load('../../data/advsql/23_employee.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "053c6576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: integer (nullable = true)\n",
      " |-- team_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "651a3a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+\n",
      "|employee_id|team|\n",
      "+-----------+----+\n",
      "|          1|   3|\n",
      "|          2|   3|\n",
      "|          3|   3|\n",
      "|          4|   1|\n",
      "|          5|   2|\n",
      "|          6|   2|\n",
      "+-----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "team_df = employee_df.groupBy('team_id').agg(count(col('team_id')).alias('team'))\n",
    "\n",
    "employee_df.join(team_df,employee_df.team_id == team_df.team_id,'inner')\\\n",
    ".select('employee_id','team').orderBy('employee_id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "5351c6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+\n",
      "|employee_id|team|\n",
      "+-----------+----+\n",
      "|          1|   3|\n",
      "|          2|   3|\n",
      "|          3|   3|\n",
      "|          4|   1|\n",
      "|          5|   2|\n",
      "|          6|   2|\n",
      "+-----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_df.createOrReplaceTempView('employeedf')\n",
    "\n",
    "spark.sql('select employee_id,team from employee_df, \\\n",
    "          (select team_id,count(team_id) as team from employeedf group by team_id) as t \\\n",
    "          where  employee_df.team_id == t.team_id order by employee_id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bfa74f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
